This is my Final project for autonomous mobile robots.

Echo Location

We decided on a pretty simple goal. Can we get a robot to track and follow sound, while avoiding obstacles?

Our system overview required an Amazon dot which connected to the Amazon web services where voice processing occurred. The mobile robot was controlled wirelessly by the control computer which gave it linear and angular velocity commands. The computer was connected to a USB webcam which looked at the amazon dot. Amazon dots light up brighter in the direction the sound came from. The camera was used to determine which side lite up more.

The camera was recording a video stream of the Amazon dot. Image processing was done on each frame of the image to result in a binary image. A summation of the x and y coordinates of the white pixels gave us a center point of the white pixels. This could then be used to calculate the desired angle.

To remove some of the excess light intensity, a physical filter was applied to the image. In this case it was a cheap pair of sunglasses.





Notice as the light spins around, we are able to accurately calculate the angle and display it. Each of the images are different stages in the image processing.

The next step was implementing a Kalman filter using first principles. This was done to give us a better approximation of the angle.

Here is a test of Kalman filter were artificial input data was generated. The data, represented by the red line, is noisy. The Kalman filter gives us a much smoother approximation of the data shown in the blue line.

Finally, we tested both the angle generated by the image processing and the Kalman filter. 

(pause)

You can see that the Kalman filter gives a much smoother angle transitions.

This information was then fed into a planner which generated velocities for our robot. Here is an example of the robot tracking my voice.

Finally, we implemented obstacle avoidance. The obstacle avoidance uses a 3D camera. This camera is a replacement for a laser scanner, and feds out sensor data. We implemented a simple algorithm which determines how close an obstacle is and which side the obstacle is.

We created a test, where the robot was told to drive straight unless there was an obstacle in its way. You will notice in the first test the robot avoids two obstacles.

In the second test, the robot avoids the first obstacle and then avoids driving into the wall.

We then put this all together. Notices the robot avoiding obstacles and moving towards the source of the sound.

Here we showed two examples of our final robot.

There are failure cases, such as when the robot starts tracking another sound.

Here the robot drives over a metal cap causing a clink sound. The robot finds the sounds is behind it and starts to turn towards it. However, the robot quickly corrects itself and drives back towards me.




